{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7223c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_folder = Path(\"./data_sirius\")\n",
    "# all_images = list(image_folder.glob(\"*.jpg\"))\n",
    "\n",
    "# save_root = Path(\"./predicted_images\")\n",
    "# original_dir = save_root / \"original\"\n",
    "# predicted_dir = save_root / \"predicted\"\n",
    "# original_dir.mkdir(parents=True, exist_ok=True)\n",
    "# predicted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Параметры\n",
    "# batch_size = 10        # размер батча для predict\n",
    "# max_images = 10_000     # максимум картинок всего\n",
    "# max_with_boxes = 1_000  # максимум картинок с боксами\n",
    "\n",
    "# images_processed = 0\n",
    "# images_with_boxes = 0\n",
    "\n",
    "# for i in range(0, min(len(all_images), max_images), batch_size):\n",
    "#     batch = all_images[i:i + batch_size]\n",
    "#     batch = [str(p) for p in batch]\n",
    "\n",
    "#     results = model.predict(\n",
    "#         source=batch,\n",
    "#         imgsz=640,\n",
    "#         conf=0.25,\n",
    "#         iou=0.1,\n",
    "#         save=False,\n",
    "#         save_txt=False,\n",
    "#     )\n",
    "\n",
    "#     for r in results:\n",
    "#         images_processed += 1\n",
    "#         if len(r.boxes) > 0:\n",
    "#             # top_conf_threshold = 0.4\n",
    "#             # min_conf = float('inf')\n",
    "#             # max_conf = float('-inf')\n",
    "#             # for box in r.boxes:\n",
    "#             #     min_conf = min(min_conf, box.conf)\n",
    "#             #     max_conf = max(max_conf, box.conf)\n",
    "\n",
    "#             # if min_conf > top_conf_threshold:\n",
    "#             #     continue\n",
    "\n",
    "#             # if max_conf > top_conf_threshold:\n",
    "#             #     continue\n",
    "\n",
    "#             images_with_boxes += 1\n",
    "\n",
    "#             orig_path = original_dir / Path(r.path).name\n",
    "#             pred_path = predicted_dir / Path(r.path).name\n",
    "\n",
    "#             # Сохраняем оригинал\n",
    "#             cv2.imwrite(str(orig_path), r.orig_img)\n",
    "\n",
    "#             # Сохраняем с бокcами\n",
    "#             annotated = r.plot()\n",
    "#             cv2.imwrite(str(pred_path), annotated)\n",
    "\n",
    "#             del annotated\n",
    "\n",
    "#         # Проверяем лимит картинок с боксами\n",
    "#         if images_with_boxes >= max_with_boxes:\n",
    "#             break\n",
    "\n",
    "#     # --- очистка памяти ---\n",
    "#     del results\n",
    "#     gc.collect()\n",
    "#     # if torch.cuda.is_available():\n",
    "#         # torch.cuda.empty_cache()\n",
    "\n",
    "#     # Проверка лимита\n",
    "#     if images_with_boxes >= max_with_boxes:\n",
    "#         print(f\"Достигнут лимит картинок с боксами: {max_with_boxes}\")\n",
    "#         break\n",
    "\n",
    "#     print(f\"Обработано картинок всего: {images_processed}, с боксами: {images_with_boxes}, доля: {images_with_boxes / images_processed}\")\n",
    "# print(f\"Обработано картинок всего: {images_processed}, с боксами: {images_with_boxes}, доля: {images_with_boxes / images_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d542f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=api_key)\n",
    "project = rf.workspace(\"nsu-sxhmy\").project(\"project_x-ar6bm\")\n",
    "version = project.version(17)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9e384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"yolov11n_train5_v17\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train5\\weights\\best.pt\"\n",
    "# name = \"yolov11n_train11_v2\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train11\\weights\\best.pt\"\n",
    "# name = \"yolov11n_train13_v3\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train13\\weights\\best.pt\"\n",
    "name = \"yolov11n_train17_v17\"\n",
    "path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train17\\weights\\best.pt\"\n",
    "# name = \"yolov11n_train18_v4_light_augh\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train18\\weights\\best.pt\"\n",
    "# name = \"yolov11m_train23_v5\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train23\\weights\\best.pt\"\n",
    "# name = \"roboflow_v5\"\n",
    "# path =r\"./roboflow_v10_dataset.pt\"\n",
    "name = \"yolov11n_train23_v17\"\n",
    "path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train23\\weights\\best.pt\"\n",
    "name = \"yolov11n_train34_v17\"\n",
    "path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train34\\weights\\best.pt\"\n",
    "# name = \"yolov11m_train35_v6\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train35\\weights\\best.pt\"\n",
    "# name = \"roboflow_v6\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\roboflow_model.pt\"\n",
    "# name = \"yolov11n_train37_v7\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train37\\weights\\best.pt\"\n",
    "# name = \"yolov11n_train38_v15\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train38\\weights\\best.pt\"\n",
    "# name = \"yolov11s_train39_v15\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train39\\weights\\best.pt\"\n",
    "# name = \"yolov11m_train40_v15\"\n",
    "# path =r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\runs\\detect\\train40\\weights\\best.pt\"\n",
    "# name = \"roboflow_yolov11s_v15___\"\n",
    "# path =r\"c:\\Users\\kuzga\\Downloads\\Telegram Desktop\\roboflow_yolov11s_v15.pt\"\n",
    "name = \"roboflow_yolov11s_v7\"\n",
    "path =r\"c:\\Users\\kuzga\\Downloads\\Telegram Desktop\\roboflow_yolo11s_v17.pt\"\n",
    "\n",
    "\n",
    "model = YOLO(path)\n",
    "# model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac5c5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.196  Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 66.744.9 MB/s, size: 43.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\project_x-7\\valid\\labels.cache... 262 images, 203 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 262/262 262.1Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 33/33 15.4it/s 2.1s0.1s\n",
      "                   all        262         75      0.973       0.96      0.974      0.875\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\kuzga\\OneDrive\\ \\CV_case_tbanc\\runs\\detect\\val37\u001b[0m\n",
      "c:\\Users\\kuzga\\Downloads\\Telegram Desktop\\roboflow_yolo11s_v17.pt\n",
      "[[    0.97414     0.97414     0.97414     0.97414     0.97414     0.97414     0.96693     0.90834     0.75174     0.28042]]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(\n",
    "    data=dataset.location + \"/data.yaml\",\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    save=True,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "valid_path = Path(f\"./validation_results_{name}\")\n",
    "valid_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(f\"{valid_path}/metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Precision: {metrics.box.mp:.3f}\\n\")\n",
    "    f.write(f\"Recall: {metrics.box.mr:.3f}\\n\")\n",
    "    f.write(f\"mAP50: {metrics.box.map50:.3f}\\n\")\n",
    "    f.write(f\"mAP50-95: {metrics.box.map:.3f}\\n\")\n",
    "\n",
    "print(path)\n",
    "print(metrics.box.all_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = valid_path / \"original\"\n",
    "predicted_dir = valid_path / \"predicted\"\n",
    "original_dir.mkdir(parents=True, exist_ok=True)\n",
    "predicted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "image_folder = Path(r\"C:\\Users\\kuzga\\OneDrive\\Рабочий стол\\CV_case_tbanc\\project_x-17\\valid\\images\")\n",
    "all_images = list(image_folder.glob(\"*.jpg\"))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "images_processed = 0\n",
    "images_with_boxes = 0\n",
    "\n",
    "print(f\"Found {len(all_images)} images\")\n",
    "for i in range(len(all_images)):\n",
    "    batch = all_images[i:i + batch_size]\n",
    "    batch = [str(p) for p in batch]\n",
    "\n",
    "    results = model.predict(\n",
    "        source=all_images[i],\n",
    "        imgsz=640,\n",
    "        conf=0.5,\n",
    "        iou=0.01,\n",
    "        save=False,\n",
    "        save_txt=False\n",
    "    )\n",
    "\n",
    "    for r in results:\n",
    "        images_processed += 1\n",
    "        # top_conf_threshold = 0.4\n",
    "        # min_conf = float('inf')\n",
    "        # max_conf = float('-inf')\n",
    "        # for box in r.boxes:\n",
    "        #     min_conf = min(min_conf, box.conf)\n",
    "        #     max_conf = max(max_conf, box.conf)\n",
    "\n",
    "        # if min_conf > top_conf_threshold:\n",
    "        #     continue\n",
    "\n",
    "        # if max_conf > top_conf_threshold:\n",
    "        #     continue\n",
    "\n",
    "        images_with_boxes += 1\n",
    "\n",
    "        orig_path = original_dir / Path(r.path).name\n",
    "        pred_path = predicted_dir / Path(r.path).name\n",
    "\n",
    "        cv2.imwrite(str(orig_path), r.orig_img)\n",
    "\n",
    "        annotated = r.plot()\n",
    "        cv2.imwrite(str(pred_path), annotated)\n",
    "\n",
    "        del annotated\n",
    "\n",
    "    del results\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "\n",
    "wrong_pred_dir = valid_path / \"wrong_predictions\"\n",
    "wrong_pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset_dir = Path(\"./project_x-17\")\n",
    "images_dir = dataset_dir / \"valid\" / \"images\"\n",
    "labels_dir = dataset_dir / \"valid\" / \"labels\"\n",
    "# images_dir = dataset_dir / \"train\" / \"images\"\n",
    "# labels_dir = dataset_dir / \"train\" / \"labels\"\n",
    "\n",
    "bad_counter = 0\n",
    "good_counter = 0\n",
    "\n",
    "\n",
    "def iou(box1, box2):\n",
    "    \"\"\"IoU между двумя bbox в формате [x1, y1, x2, y2].\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "\n",
    "def yolo2xyxy(box, w, h):\n",
    "    \"\"\"\n",
    "    YOLO формат (cx, cy, bw, bh) → (x1, y1, x2, y2) в пикселях.\n",
    "    \"\"\"\n",
    "    cx, cy, bw, bh = box\n",
    "    x1 = (cx - bw / 2) * w\n",
    "    y1 = (cy - bh / 2) * h\n",
    "    x2 = (cx + bw / 2) * w\n",
    "    y2 = (cy + bh / 2) * h\n",
    "    return [int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))]\n",
    "\n",
    "\n",
    "print(images_dir)\n",
    "for img_file in images_dir.glob(\"*.jpg\"):\n",
    "    label_file = labels_dir / (img_file.stem + \".txt\")\n",
    "    img = cv2.imread(str(img_file))\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    gt_boxes = []\n",
    "    if label_file.exists():\n",
    "        with open(label_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                cls, cx, cy, bw, bh = map(float, line.split())\n",
    "                gt_boxes.append(yolo2xyxy([cx, cy, bw, bh], w, h))\n",
    "\n",
    "\n",
    "    results = model(\n",
    "        img_file,\n",
    "        verbose=False,\n",
    "        conf=0.5,\n",
    "        iou=0.1\n",
    "    )[0]\n",
    "    pred_boxes = [box.xyxy[0].cpu().numpy().tolist() for box in results.boxes]\n",
    "\n",
    "    bad = False\n",
    "    for gt in gt_boxes:\n",
    "        if not any(iou(gt, pred) >= 0.5 for pred in pred_boxes):\n",
    "            bad = True\n",
    "    for pred in pred_boxes:\n",
    "        if not any(iou(pred, gt) >= 0.5 for gt in gt_boxes):\n",
    "            bad = True\n",
    "\n",
    "    if bad:\n",
    "        bad_counter += 1\n",
    "        shutil.copy(img_file, wrong_pred_dir / img_file.name)\n",
    "\n",
    "\n",
    "        drawn = results.plot()\n",
    "        for gt in gt_boxes:\n",
    "            x1, y1, x2, y2 = gt\n",
    "            cv2.rectangle(drawn, (x1, y1), (x2, y2), (0, 225, 0), 3)\n",
    "            cv2.putText(drawn, \"GT\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 225, 0), )\n",
    "\n",
    "        cv2.imwrite(str(wrong_pred_dir / f\"{img_file.stem}_pred.jpg\"), drawn)\n",
    "    else:\n",
    "        good_counter += 1\n",
    "\n",
    "print(f\"Все неверные предсказания сохранены в {wrong_pred_dir}\")\n",
    "print(f\"good / bad: {good_counter}, {bad_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55fb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
